{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch 기본: Tensors & Gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번 장에서 다룰 내용은 다음과 같다.:\n",
    "\n",
    "__1. 텐서(Tenosr) 소개__<br>\n",
    "__2. 텐서 연산과 기울기(Gradient)__<br>\n",
    "__3. Pytorch와 Numpy 간의 관계__<br>\n",
    "* __Pytorch Documentation__ 사이트 이용 방법\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "시작전에, <font color=red>필수 라이브러리</font>들을 설치해야한다.<br> \n",
    "PyTorch 설치방법은 사용하는 OS나 설치되는 클라우드 환경에 따라 다를 수 있다.<br>\n",
    "보다 자세한 사용법은 __PyTorch 홈페이지__를 참고: https://pytorch.org .\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch` 라이브러리를 임포트 하는 것으로 시작한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Tensors\n",
    "\n",
    "기본적으로 PyTorch는 __텐서(Tensor)__를 다루기 위한 라이브러리이다.<br>\n",
    "텐서는 __'스칼라(scalar)'__, __'벡터(vector)'__, __'행렬(matrix)'__, 또는 n차원의 배열의 형태로 존재한다.<br> \n",
    "스칼라 값을 가지는 텐서를 생성해 보도록 하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 스칼라\n",
    "t1 = torch.tensor(4.)\n",
    "t1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`4.` 은 `4.0` 을 의미한다.(축약형이다)<br> \n",
    "파이썬에서 실수형 자료형, 즉 __float__ 자료형을 표현할 때 이렇게 표현한다.<br>\n",
    "\n",
    "### 1.1 dtype\n",
    "__`dtype` 특성(attribute)__을 이용해서 텐서의 데이터 타입을 알아낼 수 있다.<br>\n",
    "<font color=blue>__dtype은 함수(methods)가 아니라 특성(attributes)__</font>이라는 점을 기억하자!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 좀 더 복잡한 텐서를 만들어 보도록 하자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4.])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 벡터(Vector)\n",
    "t2 = torch.tensor([1., 2, 3, 4])\n",
    "t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.,  6.],\n",
       "        [ 7.,  8.],\n",
       "        [ 9., 10.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 행렬(Matrix)\n",
    "t3 = torch.tensor([[5., 6], \n",
    "                   [7, 8], \n",
    "                   [9, 10]])\n",
    "t3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[11., 12., 13.],\n",
       "         [13., 14., 15.]],\n",
       "\n",
       "        [[15., 16., 17.],\n",
       "         [17., 18., 19.]]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3차원 배열\n",
    "t4 = torch.tensor([\n",
    "    [[11, 12, 13], \n",
    "     [13, 14, 15]], \n",
    "    [[15, 16, 17], \n",
    "     [17, 18, 19.]]])\n",
    "t4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 1.2 shape\n",
    "텐서는 다양한 차원, 다양한 길이. 다양한 크기로 존재할 수 있다.<br>\n",
    "따라서 __`.shape` 특성을 이용해 텐서의 모양을 알 수 있다.__<br>\n",
    "<font color=blue>__shape은 함수(methods)가 아니라 특성(attributes)__</font>이라는 점을 기억하자!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(t1)\n",
    "t1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3., 4.])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(t2)\n",
    "t2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 5.,  6.],\n",
      "        [ 7.,  8.],\n",
      "        [ 9., 10.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(t3)\n",
    "t3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[11., 12., 13.],\n",
      "         [13., 14., 15.]],\n",
      "\n",
      "        [[15., 16., 17.],\n",
      "         [17., 18., 19.]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 3])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(t4)\n",
    "t4.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여러가지 모양(shape)의 텐서가 존재가능하지만,<br>\n",
    "__부적절한 모양(주로 비어있는 값이 발생하는 경우)의 텐서는 생성될 수 없으니 주의하자!__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "expected sequence of length 3 at dim 1 (got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-83912cf67c5e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m t5 = torch.tensor([[5., 6, 11], \n\u001b[0m\u001b[0;32m      3\u001b[0m                    \u001b[1;33m[\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                    [9, 10]])\n\u001b[0;32m      5\u001b[0m \u001b[0mt5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: expected sequence of length 3 at dim 1 (got 2)"
     ]
    }
   ],
   "source": [
    "# Matrix\n",
    "t5 = torch.tensor([[5., 6, 11], \n",
    "                   [7, 8], \n",
    "                   [9, 10]])\n",
    "t5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ValueError` 오류가 발생한 이유는 `[5., 6, 11]` 행과 `[7, 8]` 행의 모양이 일치하지 않기 때문이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2.1 텐서 연산과 기울기(Gradient)\n",
    "\n",
    "텐서 연산은 일상적인 산술 연산기호('+', '*' ,' -' 등) 로 이루어진다.<br> \n",
    "몇가지 예시를 보도록 하자:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(3.), tensor(4., requires_grad=True), tensor(5., requires_grad=True))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 텐서 생성\n",
    "x = torch.tensor(3.)\n",
    "w = torch.tensor(4., requires_grad=True)\n",
    "b = torch.tensor(5., requires_grad=True)\n",
    "x, w, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "생성된 텐서는 `x`, `w`, `b` 이고 모두 스칼라 값을 가진다.<br>\n",
    "`w` 와 `b` 는 `requires_grad` 라는 추가적인 파라미터를 가지고 있으며, `True` 가 입력되어 있다.<br>\n",
    "이부분은 잠시 후에 다시 얘기 하도록하자. \n",
    "\n",
    "이 텐서들을 섞어서 `y`라는 이름의 새로운 텐서를 만들어 보자.<br>\n",
    "$$ y = w*x + b $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(17., grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 산술연산\n",
    "y = w * x + b\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예상된 것처럼, `y` 는 `3 * 4 + 5 = 17` 이라는 연산을 통해 만들어진 텐서이다.<br> \n",
    "텐서 'y'는 'w', 'x' 'b' 의 연산이 유도되어 만들어 졌다<br> \n",
    "이때 파이토치를 더욱 특별하게 만들어 주는 기능인 __'autograd(automatic gradient)'__가 작동하게 된다!<br>\n",
    "'autograd'는 'required_grad'가 'True' 로 설정된 텐서들에 대해서 <font color=red>__자동으로 기울기를 계산__</font>해 준다. <br><br>\n",
    "\n",
    "\n",
    "### Backward()\n",
    "__`.backward()`함수(Methods)__를 텐서 연산의 결과물인 `y` 에 대해 호출하는 것을 통해 식에 사용된 변수들의 기울기를 구한다.<br>\n",
    "<font color=blue>__backward()__은 함수(methods)</font>라는 점을 기억하자!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 미분 계산하기\n",
    "y.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'y.backward()' 를 통해 미분이 계산되면, `y` 를 구성했던 텐서들은 __`.grad` 특성안에 미분값을 저장__하게 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dy/dx: None\n",
      "dy/dw: tensor(3.)\n",
      "dy/db: tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "# 기울기 보이기\n",
    "print('dy/dx:', x.grad)\n",
    "print('dy/dw:', w.grad)\n",
    "print('dy/db:', b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예상되었던 대로, `dy/dw` 값은 `x` 와 같다는 점을 확인할 수 있다. <br><br>\n",
    "`x.grad` 가 `None` 으로 나왔다는 점에 주목해보자. <br>\n",
    "`x`는 __`requires_grad` 파라미터를  `True` 로 설정하지 않아서__ 기울기가 계산되지 않은 것이다.(__requires_grad의 기본값은 False라는 것을 알 수 있다!__)<br> \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 유용한 텐서 함수\n",
    "\n",
    "산술 계산을 넘어서, `torch` 라이브러리는 텐서를 생성하고 변형하는 유용한 함수들을 가지고 있다.<br>\n",
    "몇가지 예시를 보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[42, 42],\n",
       "        [42, 42],\n",
       "        [42, 42]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 고정된 값으로 텐서 원소들을 채우는 방법\n",
    "t6 = torch.full((3, 2), 42)\n",
    "t6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.,  6.],\n",
       "        [ 7.,  8.],\n",
       "        [ 9., 10.],\n",
       "        [42., 42.],\n",
       "        [42., 42.],\n",
       "        [42., 42.]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 두가지 텐서를 합치는 방법(합칠 수 있는 모양일 때만 가능하다!)\n",
    "t7 = torch.cat((t3, t6))\n",
    "t7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9589, -0.2794],\n",
       "        [ 0.6570,  0.9894],\n",
       "        [ 0.4121, -0.5440],\n",
       "        [-0.9165, -0.9165],\n",
       "        [-0.9165, -0.9165],\n",
       "        [-0.9165, -0.9165]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 각 원소들에 sin 연산을 수행하는 방법\n",
    "t8 = torch.sin(t7)\n",
    "t8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.9589, -0.2794],\n",
       "         [ 0.6570,  0.9894]],\n",
       "\n",
       "        [[ 0.4121, -0.5440],\n",
       "         [-0.9165, -0.9165]],\n",
       "\n",
       "        [[-0.9165, -0.9165],\n",
       "         [-0.9165, -0.9165]]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 텐서의 모양을 바꾸는 방법(매우 많이 사용되고 유용한 방법이니 꼭 숙지하도록 하자!!)\n",
    "t9 = t8.reshape(3, 2, 2)\n",
    "t9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여러가지 함수들에 대한 정보는 다음 웹페이지에서 확인할 수 있다.: https://pytorch.org/docs/stable/torch.html . <br>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Numpy와의 관계\n",
    "\n",
    "[Numpy](http://www.numpy.org/) 는 __수학적, 과학적 계산에 유용한 함수__들을 제공하는 파이썬 라이브러리이다.<br> \n",
    "Numpy 뿐만아니라, 다양한 라이브러리들의 유용한 함수들도 존재한다.\n",
    "\n",
    "* [Pandas](https://pandas.pydata.org/) __파일 입출력과 데이터 분석에 유용한 함수들을 제공__\n",
    "* [Matplotlib](https://matplotlib.org/) __그래프 그리기와 시각화에 유용한 함수들을 제공__\n",
    "* [OpenCV](https://opencv.org/) __이미지와 비디오 처리에 유용한 함수들을 제공__\n",
    "\n",
    "파이토치는 Numpy와 호환성이 높아 NUmpy에 존재하는 유용한 함수들과 환경들을 사용할 수 있다는 장점이 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy 배열을 생성하는 방법은 아래와 같다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2.],\n",
       "       [3., 4.]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.array([[1, 2], [3, 4.]])\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch.from_numpy` 함수를 사용하면 간단하게 __넘파이 배열을 파이토치 텐서로__ 바꿀 수도 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 넘파이 배열을 파이토치 텐서로 바꾸기.\n",
    "y = torch.from_numpy(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy 배열과 Pytorch 텐서가 비슷한 데이터 타입을 가지고 있다는 것을 확인해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('float64'), torch.float64)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.dtype, y.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "반대로 `.numpy` 함수를 이용하면 __파이토치 텐서를 넘파이 배열__로 바꿀 수도 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2.],\n",
       "       [3., 4.]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 파이토치 텐서를 넘파이 배열로 바꾸기\n",
    "z = y.numpy()\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "대부분의 데이터셋들이 Numpy 배열로 구성되어 있고, Numpy를 이용해 처리하기 쉽기 때문에,<br>\n",
    "__<font color=red>Numpy와 PyTorch의 호환성</font>은 매우 중요하다.__<br>\n",
    "그렇다면 __\"Numpy 자료구조가 이미 존재하는데 추가적으로 텐서라는 자료구조가 필요한 이유가 있어야하는가\"__라는 의문이 생긴다.<br> \n",
    "그러나 텐서에는 __2가지 중요한 존재의 이유__가 있다:\n",
    "<font color=blue>\n",
    "1. **Autograd**: 딥러닝 모델에서 학습과정에는 텐서에 대한 기울기 연산을 자동으로 해주는 기능이 필수적이다.\n",
    "2. **GPU support**: 대량의 데이터셋과 복잡한 모델이 작동하기 위해서, 파이토치 텐서는 그래픽카드(GPU: Graphics Processing Unit)를 사용할 수 있다.  GPU를 사용하면 몇시간이 걸리는 복잡한 연산도 몇분만에 해낼 수 있다!\n",
    "</font>\n",
    "우리는 이와 같은 장점들을 튜토리얼 전반에 걸쳐서 사용할 것이다\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 내용 요약 \n",
    "\n",
    "이번 장에서는 다음과 같은 내용들을 다루었다\n",
    "\n",
    "* __파이토치 텐서의 소개__\n",
    "* __텐서 연산과 기울기__\n",
    "* __파이토치와 넘파이의 관계__\n",
    "\n",
    "\n",
    "__파이토치 텐서에 대해서는 다음 웹페이지를 통해 더 배울 수 있습니다.__ : https://pytorch.org/docs/stable/tensors.html. \n",
    "\n",
    "\n",
    "본자료는 다음 자료들을 참고하여 제작되었습니다:\n",
    "\n",
    "* [PyTorch Tutorial for Deep Learning Researchers](https://github.com/yunjey/pytorch-tutorial) by Yunjey Choi \n",
    "* [FastAI development notebooks](https://github.com/fastai/fastai_docs/tree/master/dev_nb) by Jeremy Howard. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions for Review\n",
    "\n",
    "Try answering the following questions to test your understanding of the topics covered in this notebook:\n",
    "\n",
    "1. What is PyTorch?\n",
    "2. What is a Jupyter notebook?\n",
    "3. What is Google Colab?\n",
    "4. How do you install PyTorch?\n",
    "5. How do you import the `torch` module?\n",
    "6. What is a vector? Give an example.\n",
    "7. What is a matrix? Give an example.\n",
    "8. What is a tensor?\n",
    "9. How do you create a PyTorch tensor? Illustrate with examples.\n",
    "10. What is the difference between a tensor and a vector or a matrix?\n",
    "11. Is every tensor a matrix?\n",
    "12. Is every matrix a tensor?\n",
    "13. What does the `dtype` property of a tensor represent?\n",
    "14. Is it possible to create a tensor with elements of different data types?\n",
    "15. How do you inspect the number of dimensions of a tensor and the length along each dimension?\n",
    "16. Is it possible to create a tensor with the values `[[1, 2, 3], [4, 5]]`? Why or why not?\n",
    "17. How do you perform arithmetic operations on tensors? Illustrate with examples?\n",
    "18. What happens if you specify `requires_grad=True` while creating a tensor? Illustrate with an example.\n",
    "19. What is autograd in PyTorch? How is it useful?\n",
    "20. What happens when you invoke  the `backward` method of a tensor?\n",
    "21. How do you check the derivates of a result tensor w.r.t. the tensors used to compute its value?\n",
    "22. Give some examples of functions available in the `torch` module for creating tensors.\n",
    "23. Give some examples of functions available in the `torch` module for performing mathematical operations on tensors.\n",
    "24. Where can you find the list of tensor operations available in PyTorch?\n",
    "25. What is Numpy?\n",
    "26. How do you create a Numpy array?\n",
    "27. How do you create a PyTorch tensor using a Numpy array?\n",
    "28. How do you create a Numpy array using a PyTorch tensor?\n",
    "29. Why is interoperability between PyTorch and Numpy important?\n",
    "30. What is the purpose of a library like PyTorch if Numpy already provides data structures and utilities to with multi-dimensional numeric data?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
