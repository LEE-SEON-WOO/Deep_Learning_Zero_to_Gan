{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# PyTorch 기본: Tensors & Gradients"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "이번 장에서 다룰 내용은 다음과 같다.:\n",
    "\n",
    "__1. 텐서(Tenosr) 소개__<br>\n",
    "__2. 텐서 연산과 기울기(Gradient)__<br>\n",
    "__3. Pytorch와 Numpy 간의 관계__<br>\n",
    "* __Pytorch Documentation__ 사이트 이용 방법\n",
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "시작전에, <font color=red>필수 라이브러리</font>들을 설치해야한다.<br> \n",
    "PyTorch 설치방법은 사용하는 OS나 설치되는 클라우드 환경에 따라 다를 수 있다.<br>\n",
    "보다 자세한 사용법은 __PyTorch 홈페이지__를 참고: https://pytorch.org .\n",
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "`torch` 라이브러리를 임포트 하는 것으로 시작한다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "import torch"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 1. Tensors\n",
    "\n",
    "기본적으로 PyTorch는 __텐서(Tensor)__를 다루기 위한 라이브러리이다.<br>\n",
    "텐서는 __'스칼라(scalar)'__, __'벡터(vector)'__, __'행렬(matrix)'__, 또는 n차원의 배열의 형태로 존재한다.<br> \n",
    "스칼라 값을 가지는 텐서를 생성해 보도록 하자."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "# 스칼라\r\n",
    "t1 = torch.tensor(4.)\r\n",
    "t1"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(4.)"
      ]
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "`4.` 은 `4.0` 을 의미한다.(축약형이다)<br> \n",
    "파이썬에서 실수형 자료형, 즉 __float__ 자료형을 표현할 때 이렇게 표현한다.<br>\n",
    "\n",
    "### 1.1 dtype\n",
    "__`dtype` 특성(attribute)__을 이용해서 텐서의 데이터 타입을 알아낼 수 있다.<br>\n",
    "<font color=blue>__dtype은 함수(methods)가 아니라 특성(attributes)__</font>이라는 점을 기억하자!!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "t1.dtype"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "이제 좀 더 복잡한 텐서를 만들어 보도록 하자"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "# 벡터(Vector)\r\n",
    "t2 = torch.tensor([1., 2, 3, 4])\r\n",
    "t2"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4.])"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "# 행렬(Matrix)\r\n",
    "t3 = torch.tensor([[5., 6], \r\n",
    "                   [7, 8], \r\n",
    "                   [9, 10]])\r\n",
    "t3"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[ 5.,  6.],\n",
       "        [ 7.,  8.],\n",
       "        [ 9., 10.]])"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "# 3차원 배열\r\n",
    "t4 = torch.tensor([\r\n",
    "    [[11, 12, 13], \r\n",
    "     [13, 14, 15]], \r\n",
    "    [[15, 16, 17], \r\n",
    "     [17, 18, 19.]]])\r\n",
    "t4"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[11., 12., 13.],\n",
       "         [13., 14., 15.]],\n",
       "\n",
       "        [[15., 16., 17.],\n",
       "         [17., 18., 19.]]])"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "### 1.2 shape\n",
    "텐서는 다양한 차원, 다양한 길이. 다양한 크기로 존재할 수 있다.<br>\n",
    "따라서 __`.shape` 특성을 이용해 텐서의 모양을 알 수 있다.__<br>\n",
    "<font color=blue>__shape은 함수(methods)가 아니라 특성(attributes)__</font>이라는 점을 기억하자!!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "print(t1)\r\n",
    "t1.shape"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor(4.)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "print(t2)\r\n",
    "t2.shape"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([1., 2., 3., 4.])\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([4])"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "print(t3)\r\n",
    "t3.shape"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[ 5.,  6.],\n",
      "        [ 7.,  8.],\n",
      "        [ 9., 10.]])\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "print(t4)\r\n",
    "t4.shape"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[[11., 12., 13.],\n",
      "         [13., 14., 15.]],\n",
      "\n",
      "        [[15., 16., 17.],\n",
      "         [17., 18., 19.]]])\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 3])"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "여러가지 모양(shape)의 텐서가 존재가능하지만,<br>\n",
    "__부적절한 모양(주로 비어있는 값이 발생하는 경우)의 텐서는 생성될 수 없으니 주의하자!__"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "# Matrix\r\n",
    "t5 = torch.tensor([[5., 6, 11], \r\n",
    "                   [7, 8], \r\n",
    "                   [9, 10]])\r\n",
    "t5"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "expected sequence of length 3 at dim 1 (got 2)",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-83912cf67c5e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m t5 = torch.tensor([[5., 6, 11], \n\u001b[0m\u001b[0;32m      3\u001b[0m                    \u001b[1;33m[\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                    [9, 10]])\n\u001b[0;32m      5\u001b[0m \u001b[0mt5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: expected sequence of length 3 at dim 1 (got 2)"
     ]
    }
   ],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "`ValueError` 오류가 발생한 이유는 `[5., 6, 11]` 행과 `[7, 8]` 행의 모양이 일치하지 않기 때문이다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 2.1 텐서 연산과 기울기(Gradient)\n",
    "\n",
    "텐서 연산은 일상적인 산술 연산기호('+', '*' ,' -' 등) 로 이루어진다.<br> \n",
    "몇가지 예시를 보도록 하자:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "# 텐서 생성\r\n",
    "x = torch.tensor(3.)\r\n",
    "w = torch.tensor(4., requires_grad=True)\r\n",
    "b = torch.tensor(5., requires_grad=True)\r\n",
    "x, w, b"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor(3.), tensor(4., requires_grad=True), tensor(5., requires_grad=True))"
      ]
     },
     "metadata": {},
     "execution_count": 55
    }
   ],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "생성된 텐서는 `x`, `w`, `b` 이고 모두 스칼라 값을 가진다.<br>\n",
    "`w` 와 `b` 는 `requires_grad` 라는 추가적인 파라미터를 가지고 있으며, `True` 가 입력되어 있다.<br>\n",
    "이부분은 잠시 후에 다시 얘기 하도록하자. \n",
    "\n",
    "이 텐서들을 섞어서 `y`라는 이름의 새로운 텐서를 만들어 보자.<br>\n",
    "$$ y = w*x + b $$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "# 산술연산\r\n",
    "y = w * x + b\r\n",
    "y"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(17., grad_fn=<AddBackward0>)"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "예상된 것처럼, `y` 는 `3 * 4 + 5 = 17` 이라는 연산을 통해 만들어진 텐서이다.<br> \n",
    "텐서 'y'는 'w', 'x' 'b' 의 연산이 유도되어 만들어 졌다<br> \n",
    "이때 파이토치를 더욱 특별하게 만들어 주는 기능인 __'autograd(automatic gradient)'__가 작동하게 된다!<br>\n",
    "'autograd'는 'required_grad'가 'True' 로 설정된 텐서들에 대해서 <font color=red>__자동으로 기울기를 계산__</font>해 준다. <br><br>\n",
    "\n",
    "\n",
    "### Backward()\n",
    "__`.backward()`함수(Methods)__를 텐서 연산의 결과물인 `y` 에 대해 호출하는 것을 통해 식에 사용된 변수들의 기울기를 구한다.<br>\n",
    "<font color=blue>__backward()__은 함수(methods)</font>라는 점을 기억하자!!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "# 미분 계산하기\r\n",
    "y.backward()"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "'y.backward()' 를 통해 미분이 계산되면, `y` 를 구성했던 텐서들은 __`.grad` 특성안에 미분값을 저장__하게 된다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "# 기울기 보이기\r\n",
    "print('dy/dx:', x.grad)\r\n",
    "print('dy/dw:', w.grad)\r\n",
    "print('dy/db:', b.grad)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dy/dx: None\n",
      "dy/dw: tensor(3.)\n",
      "dy/db: tensor(1.)\n"
     ]
    }
   ],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "예상되었던 대로, `dy/dw` 값은 `x` 와 같다는 점을 확인할 수 있다. <br><br>\n",
    "`x.grad` 가 `None` 으로 나왔다는 점에 주목해보자. <br>\n",
    "`x`는 __`requires_grad` 파라미터를  `True` 로 설정하지 않아서__ 기울기가 계산되지 않은 것이다.(__requires_grad의 기본값은 False라는 것을 알 수 있다!__)<br> \n",
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.2 유용한 텐서 함수\n",
    "\n",
    "산술 계산을 넘어서, `torch` 라이브러리는 텐서를 생성하고 변형하는 유용한 함수들을 가지고 있다.<br>\n",
    "몇가지 예시를 보자"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "# 고정된 값으로 텐서 원소들을 채우는 방법\r\n",
    "t6 = torch.full((3, 2), 42)\r\n",
    "t6"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[42, 42],\n",
       "        [42, 42],\n",
       "        [42, 42]])"
      ]
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "# 두가지 텐서를 합치는 방법(합칠 수 있는 모양일 때만 가능하다!)\r\n",
    "t7 = torch.cat((t3, t6))\r\n",
    "t7"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[ 5.,  6.],\n",
       "        [ 7.,  8.],\n",
       "        [ 9., 10.],\n",
       "        [42., 42.],\n",
       "        [42., 42.],\n",
       "        [42., 42.]])"
      ]
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "# 각 원소들에 sin 연산을 수행하는 방법\r\n",
    "t8 = torch.sin(t7)\r\n",
    "t8"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[-0.9589, -0.2794],\n",
       "        [ 0.6570,  0.9894],\n",
       "        [ 0.4121, -0.5440],\n",
       "        [-0.9165, -0.9165],\n",
       "        [-0.9165, -0.9165],\n",
       "        [-0.9165, -0.9165]])"
      ]
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "# 텐서의 모양을 바꾸는 방법(매우 많이 사용되고 유용한 방법이니 꼭 숙지하도록 하자!!)\r\n",
    "t9 = t8.reshape(3, 2, 2)\r\n",
    "t9"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[-0.9589, -0.2794],\n",
       "         [ 0.6570,  0.9894]],\n",
       "\n",
       "        [[ 0.4121, -0.5440],\n",
       "         [-0.9165, -0.9165]],\n",
       "\n",
       "        [[-0.9165, -0.9165],\n",
       "         [-0.9165, -0.9165]]])"
      ]
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "여러가지 함수들에 대한 정보는 다음 웹페이지에서 확인할 수 있다.: https://pytorch.org/docs/stable/torch.html . <br>\n",
    "\n",
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Numpy와의 관계\n",
    "\n",
    "[Numpy](http://www.numpy.org/) 는 __수학적, 과학적 계산에 유용한 함수__들을 제공하는 파이썬 라이브러리이다.<br> \n",
    "Numpy 뿐만아니라, 다양한 라이브러리들의 유용한 함수들도 존재한다.\n",
    "\n",
    "* [Pandas](https://pandas.pydata.org/) __파일 입출력과 데이터 분석에 유용한 함수들을 제공__\n",
    "* [Matplotlib](https://matplotlib.org/) __그래프 그리기와 시각화에 유용한 함수들을 제공__\n",
    "* [OpenCV](https://opencv.org/) __이미지와 비디오 처리에 유용한 함수들을 제공__\n",
    "\n",
    "파이토치는 Numpy와 호환성이 높아 NUmpy에 존재하는 유용한 함수들과 환경들을 사용할 수 있다는 장점이 있다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Numpy 배열을 생성하는 방법은 아래와 같다:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "import numpy as np\r\n",
    "\r\n",
    "x = np.array([[1, 2], [3, 4.]])\r\n",
    "x"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[1., 2.],\n",
       "       [3., 4.]])"
      ]
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "`torch.from_numpy` 함수를 사용하면 간단하게 __넘파이 배열을 파이토치 텐서로__ 바꿀 수도 있다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "# 넘파이 배열을 파이토치 텐서로 바꾸기.\r\n",
    "y = torch.from_numpy(x)\r\n",
    "y"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]], dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Numpy 배열과 Pytorch 텐서가 비슷한 데이터 타입을 가지고 있다는 것을 확인해보자"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "x.dtype, y.dtype"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(dtype('float64'), torch.float64)"
      ]
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "반대로 `.numpy` 함수를 이용하면 __파이토치 텐서를 넘파이 배열__로 바꿀 수도 있다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "# 파이토치 텐서를 넘파이 배열로 바꾸기\r\n",
    "z = y.numpy()\r\n",
    "z"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[1., 2.],\n",
       "       [3., 4.]])"
      ]
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "대부분의 데이터셋들이 Numpy 배열로 구성되어 있고, Numpy를 이용해 처리하기 쉽기 때문에,<br>\n",
    "__<font color=red>Numpy와 PyTorch의 호환성</font>은 매우 중요하다.__<br>\n",
    "그렇다면 __\"Numpy 자료구조가 이미 존재하는데 추가적으로 텐서라는 자료구조가 필요한 이유가 있어야하는가\"__라는 의문이 생긴다.<br> \n",
    "그러나 텐서에는 __2가지 중요한 존재의 이유__가 있다:\n",
    "<font color=blue>\n",
    "1. **Autograd**: 딥러닝 모델에서 학습과정에는 텐서에 대한 기울기 연산을 자동으로 해주는 기능이 필수적이다.\n",
    "2. **GPU support**: 대량의 데이터셋과 복잡한 모델이 작동하기 위해서, 파이토치 텐서는 그래픽카드(GPU: Graphics Processing Unit)를 사용할 수 있다.  GPU를 사용하면 몇시간이 걸리는 복잡한 연산도 몇분만에 해낼 수 있다!\n",
    "</font>\n",
    "우리는 이와 같은 장점들을 튜토리얼 전반에 걸쳐서 사용할 것이다\n",
    "\n",
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 내용 요약 \n",
    "\n",
    "이번 장에서는 다음과 같은 내용들을 다루었다\n",
    "\n",
    "* __파이토치 텐서의 소개__\n",
    "* __텐서 연산과 기울기__\n",
    "* __파이토치와 넘파이의 관계__\n",
    "\n",
    "\n",
    "__파이토치 텐서에 대해서는 다음 웹페이지를 통해 더 배울 수 있습니다.__ : https://pytorch.org/docs/stable/tensors.html. \n",
    "\n",
    "\n",
    "본자료는 다음 자료들을 참고하여 제작되었습니다:\n",
    "\n",
    "* [PyTorch Tutorial for Deep Learning Researchers](https://github.com/yunjey/pytorch-tutorial) by Yunjey Choi \n",
    "* [FastAI development notebooks](https://github.com/fastai/fastai_docs/tree/master/dev_nb) by Jeremy Howard. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 복습을 위한 질문\r\n",
    "\r\n",
    "이 노트북에서 다루는 주제에 대한 이해도를 테스트하기 위해 다음 질문에 답해 보십시오.\r\n",
    "\r\n",
    "1. 파이토치란?\r\n",
    "2. Jupyter 노트북이란 무엇인지?\r\n",
    "3. Google Colab이란 무엇인지?\r\n",
    "4. PyTorch를 어떻게 설치하는지?\r\n",
    "5. 'torch' 모듈을 어떻게 가져오는지?\r\n",
    "6. 벡터란 무엇인지? 예를 들어 주십시오.\r\n",
    "7. 행렬이란 무엇인지? 예를 들어 주십시오.\r\n",
    "8. 텐서란 무엇인지?\r\n",
    "9. PyTorch 텐서는 어떻게 생성합니까? 예를 들어 설명합니다.\r\n",
    "10. 텐서와 벡터 또는 행렬의 차이점은 무엇인지?\r\n",
    "11. 모든 텐서는 행렬인지?\r\n",
    "12. 모든 행렬이 텐서인지?\r\n",
    "13. 텐서의 'dtype' 속성은 무엇을 나타내는지 설명해보세요\r\n",
    "14. 다른 데이터 유형의 요소로 텐서를 생성할 수 있는지?\r\n",
    "15. 텐서의 차원 수와 각 차원의 길이를 어떻게 검사하는지?\r\n",
    "16. 값이 `[[1, 2, 3], [4, 5]]`인 텐서를 생성할 수 있고 그 이유는 무엇인지 설명해보세요.\r\n",
    "17. 텐서에서 산술 연산을 어떻게 수행하는지 예를 들어 설명해 보세요.\r\n",
    "18. 텐서를 생성하는 동안 `requires_grad=True`를 지정하면 어떻게 되는지 예를 들어 설명해 보세요.\r\n",
    "19. PyTorch에서 autograd는 무엇인지 어떻게 유용한지 설명해보세요.\r\n",
    "20. 텐서의 'backward' 메서드를 호출하면 어떻게 되는지 설명해보세요.\r\n",
    "21. 도함수(derivate)을 어떻게 확인하는지 그 값을 계산하는하는데 사용되는 텐서는?\r\n",
    "22. 텐서를 생성하기 위해 `torch` 모듈에서 사용할 수 있는 함수의 몇 가지 예를 제시해 보세요.\r\n",
    "23. 텐서에 대한 수학 연산을 수행하기 위해 `torch` 모듈에서 사용할 수 있는 함수의 몇 가지 예를 제시해 보세요.\r\n",
    "24. PyTorch에서 사용할 수 있는 텐서 작업 목록은 어디에서 찾을 수 있는지?\r\n",
    "25. Numpy가 무엇인지 설명해보세요.\r\n",
    "26. Numpy 배열은 어떻게 생성하는지 설명해보세요.\r\n",
    "27. Numpy 배열을 사용하여 PyTorch 텐서를 어떻게 생성하는지 설명해보세요.\r\n",
    "28. PyTorch 텐서를 사용하여 Numpy 배열을 어떻게 생성하는지 설명해보세요.\r\n",
    "29. PyTorch와 Numpy 간의 상호 운용성이 중요한 이유는 무엇인지 설명해보세요.\r\n",
    "30. Numpy가 이미 다차원 숫자 데이터에 대한 데이터 구조와 유틸리티를 제공한다면 PyTorch와 같은 라이브러리의 목적은 무엇인지 설명해보세요."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {
    "collapsed": true
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}